Привер, Хабр!

В копилку постов про DeepSeek, о котором не писал разве что совсем ленивый хочу забросить ещё пять копеек в виде практического отчёта о инсталляции на Xeon, о котором меня попросили в комментариях. Кому любопытно - может заглянуть под кат, ну а тем, кто уже выполнил упражнение по установке - будет совершенно неинтересно.

Прикоснуться к ИИ.

Спойлер для экономии времени читающих - я просто скачаю DeepSeek и запущу его через llama.cpp, на какую-либо научную новизну этот пост совершенно не претендует. Зачем это на хабре? Просто в комментариях к посту "" я спросил "имеете ли смысл попробовать на том железе, что у меня есть", и некоторое количество "плюсиков" говорит о том, что кому-нибудь это будет интересно, ну а раз паззл сложился - о том и пост, просто развёрнутое продолжение к предыдущему.

Второй спойлер - да это работает. Но очень медленно. Но работает.

### Железо

Упражняться я буду вот на такой конфигурации:

HP z8 рабочая станция примерно четырёхлетней давности. Два процессора Xeon Gold, 768 GB памяти DDR4, терабайтный NVMe SSD Samsung. Видеокарт там две - NVidia Quadro K4200 да AMD, но использоваться как GPU они не будут (смысла в общем нет).

Комп остался как тестовый от одного проекта,  в котором надо быстро обрабатывать 640 GB картинок, прилетающих от нескольких скоростных камер, теперь просто пылится под столом и эпизодически используется для упражнений.

Бенчмарки:

SSD.

### Скачиваем DeepSeek R0

Я бы мог просто написать "скачайте DeepSeek", но тут есть небольшой нюанс. Дело в том, что на работе у меня все искусственные интеллекты старательно заблокированы злым админом, охраняющим интеллектуальную собственность. У меня нет онлайн доступа ни к ChatGPT, ни к Perplexity, ни к DeepSeek, равно как все дропбоксы, гуглодрайвы, онлайн заметочники - блокировано решительно всё. Причём не только на уровне прокси, но также фактически осуществляется MITM подменой сертификата, поэтому скачать с huggingface я ничего не могу, получая отлуп 500. Издержки работы в большой компании. Так что качать я буду дома. А дома у меня всего-навсего 100 мбит оптоволокно, так что процесс не быстрый (планируйте больше суток).

Поскольку репозиторий содержит несколько моделей, то я решил, что я самый умный, и слегка погуглив нашёл способ выдернуть через гит отдельную папку.

Вот так это делается:

```
git ...
```

Я включил старый комп с файлопомойкой , проверил там свободноее место, выполнил команды выше и пошёл спать. Наутро я обнаружил, что туда прилетели обновления и он перезагрузился. Ну, бывает.

Лирическое отступление - если вы хотите временно отказаться от обновлений, то просто включите Metered Network, это самый наипростейший способ.

Я это сделал, и выполнив команды второй раз, обнаружил, что "докачки" там нет и в помине, git начал качать с нуля (это видно в кеше). Тогда я включил древний QNAP NAS, там есть качалка, но тут меня ждала другая засада - раз в сутки провайдер сбрасывает соединение, при этом NAS вываливал ошибку и начинал скачку снова. Я уже хотел было отказаться от затеи, но если я во всеуслышаение напишу здесь, что не смог скачать шестьсот гиг, то надо мной будет ржать весь хабр, и я буду подвергнут публичному остракизму, так что пришлось расчехлить  менеджер закачек, которым я не пользовался уже много лет.

Я это к тому, что если захотите скачать — заранее проверьте, что вы можете докачивать при обрыве соединения.

Как бы то ни было, вот репозиторий, вот модель, а под спойлером - прямые ссылки на список файлов, которые можно скормить любому менеджеру, я пользовался [JDownloader 2](https://jdownloader.org/download/index).

Пока идёт скачивание, чтоб было не скучно - могу предложить загадку.

Во второй половине девяностых, мы, новоиспечённые выпускники - физики иногда собиралсь вместе, распивали крепкие спиртные напитки и иногда смотрели фильмы на видеокассетах. В числе наиболее популярных был фильм, который мы называли не иначе как "это наше кино, про эти, про ГИГАБАЙТЫ!" Угадайте, о каком фильме, выпущенном в середине девяностых, шла речь?

Как бы то ни было, через пару дней на гигабайтном диске у меня лежали пятнадцать заветных файлов. Испытал странное ощущение - это у меня в руках почти весь запас знаний?

### Запускаем.

Вообще говоря существует несколько способов "запустить" DeepSeek - LM Studio, Ollama, llama.ccp и OpenVINO. Я попробовал навскидку все, но без фанатизма.

Самый наипростейший - LM Studio. Актуальная версия 3.9.6. Я попробовал поставить дома, всё без проблем, как демка скачивается простенькая DeepSeek R1 Distilled (Qwen 7B) на 4 с половиной гига, что позволяет запустить это дело даже на моём древнем ноуте (32 ГБ, процессор i7-4940MX). Я попробовал - даже работает, но очень медленно.

Я закинул на диск инсталлятор, но на hp z8 меня ждал облом - "тестовая" Qwen 7B загружалась, но вываливалась в ошибку после первого же промпта, а Q0 отказалась загружаться вовсе, сославшись на нехватку ресурсов. Дальше я пробовать не стал.

Ollama в основном рассчитана на то, что скачивать модель вы будете через неё же (что невозможно в моём случае), а вот как подоткнуть ей уже скачаннные файлы - я не нашёл. То есть место-то где они должны лежать я знаю, но там надо добавить конфигурационный файл, в общем она файлы модели не увидела.

А вот с llama.ccp всё получилось, и очень просто. Я было приготовился долго и нудно собирать это дело из исходников, но делать это не надо, там есть билды под Windows. Поскольку у меня железка на Xeon, то есть AVX512, вот эту версию я и скачал.

Забрасываем файлы модели и содержимое архива в одну папку и запускаем:

```
cli
```

Все параметры командной строки (на английском, под спойлером):

```
<spoiler>
```

### "Работаем"

Ну вот прям "работой" это назвать сложно, потому что это всё отчаянно медленно.

Сразу после запуска модель целиком в память не грузится, она как бы "догружается" при общении.

Вот занятая память